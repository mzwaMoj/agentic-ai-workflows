{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f818581a",
   "metadata": {},
   "source": [
    "# Lesson 5: Document RAG with LlamaIndex\n",
    "\n",
    "In this lesson, we'll learn how to create a Retrieval-Augmented Generation (RAG) system that can process and query documents using LlamaIndex. This approach allows our AI agent to answer questions based on specific document content, making it perfect for document analysis, knowledge bases, and content-specific Q&A systems.\n",
    "\n",
    "We'll build a complete document RAG solution that can handle multiple document formats and provide accurate, source-attributed responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dd7803",
   "metadata": {},
   "source": [
    "## Lesson Objectives\n",
    "\n",
    "By the end of this lesson, you will be able to:\n",
    "\n",
    "1. Set up and configure LlamaIndex for document processing\n",
    "2. Load and index various document formats (text, PDF, Word, etc.)\n",
    "3. Create vector embeddings for semantic search\n",
    "4. Build a basic RAG pipeline for document Q&A\n",
    "5. Implement advanced retrieval strategies and filtering\n",
    "6. Use LlamaIndex agents for complex document analysis\n",
    "7. Create a conversational interface for document exploration\n",
    "8. Handle multi-document queries and source attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ca23a3",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, let's set up our environment with the necessary libraries for document RAG.\n",
    "\n",
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex \n",
    "- !pip install llama-index-embeddings-openai\n",
    "- !pip install llama-index-llms-openai\n",
    "- !pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a82e1508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "# !pip install llama-index openai python-dotenv tiktoken chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e76b705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# LlamaIndex imports\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex, \n",
    "    SimpleDirectoryReader, \n",
    "    StorageContext, \n",
    "    load_index_from_storage,\n",
    "    Settings\n",
    ")\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# logging.basicConfig(\n",
    "#     stream=sys.stdout, level=logging.INFO\n",
    "# )  # logging.DEBUG for more verbose output\n",
    "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "\n",
    "# Additional utilities\n",
    "from IPython.display import display, Markdown\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a352106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API keys and configuration\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "MODEL = os.environ.get(\"OPENAI_MODEL\", \"gpt-4.1\")\n",
    "EMBEDDING_MODEL = os.environ.get(\"OPENAI_EMBEDDING_MODEL\", \"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc5b34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI API key loaded successfully\n",
      "üìã Using model: gpt-4.1\n",
      "üìã Using embedding model: text-embedding-3-large\n"
     ]
    }
   ],
   "source": [
    "# Check if the necessary API keys are available\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"‚ö†Ô∏è OpenAI API key not found. Please set the OPENAI_API_KEY environment variable.\")\n",
    "else:\n",
    "    print(\"‚úÖ OpenAI API key loaded successfully\")\n",
    "    print(f\"üìã Using model: {MODEL}\")\n",
    "    print(f\"üìã Using embedding model: {EMBEDDING_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1397e69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI LLM for LlamaIndex\n",
    "llm = OpenAI(\n",
    "    model=MODEL,\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# Configure embedding model\n",
    "embed_model = OpenAIEmbedding(\n",
    "    model=EMBEDDING_MODEL,\n",
    "    api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6769b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß LlamaIndex configured with OpenAI\n",
      "üìä Chunk size: 1024\n",
      "üìä Chunk overlap: 200\n"
     ]
    }
   ],
   "source": [
    "# Set global configurations for LlamaIndex\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.chunk_size = 1024\n",
    "Settings.chunk_overlap = 200\n",
    "\n",
    "print(\"üîß LlamaIndex configured with OpenAI\")\n",
    "print(f\"üìä Chunk size: {Settings.chunk_size}\")\n",
    "print(f\"üìä Chunk overlap: {Settings.chunk_overlap}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78c7a87",
   "metadata": {},
   "source": [
    "## 2. Loading and Processing Documents\n",
    "\n",
    "Let's start by loading and processing our sample documents. LlamaIndex makes it easy to load various document formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7f7b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    input_dir=\"../lesson_5_document_rag/sample_documents\", # provide the path to your documents here\n",
    ").load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8935b99",
   "metadata": {},
   "source": [
    "## 3. Creating Vector Index\n",
    "\n",
    "Now let's create a vector index from our documents. This will enable semantic search over the document content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d86fcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 06:46:22,772 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eb12fa",
   "metadata": {},
   "source": [
    "## 4. Basic RAG Query Engine\n",
    "\n",
    "Let's create a basic query engine that can answer questions based on our document content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de14c044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 06:49:27,295 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-03 06:49:30,039 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**query was:**\n",
      " What are these documents about?\n",
      "\n",
      "**answer was:**\n",
      " The first document provides a comprehensive overview of Artificial Intelligence (AI) and Machine Learning (ML), explaining their definitions, types, fundamental concepts, applications across various industries such as healthcare, finance, transportation, and technology, as well as the challenges and future outlook associated with these technologies.\n",
      "\n",
      "The second document discusses key trends and strategies in cloud computing, including serverless computing, container orchestration, multi-cloud and hybrid strategies, and the integration of AI and ML services. It also explores the future direction of cloud computing, highlighting advancements like edge computing, sustainability, enhanced security, automation, and quantum computing, and emphasizes the importance of strategic cloud adoption for organizations.\n",
      "============================================================\n",
      "**sources were:**\n",
      "> Source (Doc id: 9283ea4a-c377-453b-aebd-f2b61c142d8c): Artificial Intelligence and Machine Learning: A Comprehensive Overview\n",
      "\n",
      "Introduction\n",
      "\n",
      "Artificial ...\n",
      "\n",
      "> Source (Doc id: fe37a6c8-fe17-4ea8-a935-999f4116c18d): Serverless Computing:\n",
      "Running applications without managing servers, paying only for actual usage...\n"
     ]
    }
   ],
   "source": [
    "query = \"What are these documents about?\"\n",
    "query_engine = index.as_query_engine()\n",
    "answer = query_engine.query(query)\n",
    "\n",
    "print(\"\\n\\n**query was:**\\n\", query)\n",
    "print(\"\\n**answer was:**\\n\", answer)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"**sources were:**\")\n",
    "print(answer.get_formatted_sources())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bec03f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the basic query engine\n",
    "def test_basic_query(question):\n",
    "    \"\"\"Test a query and display results\"\"\"\n",
    "    print(f\"üîç Question: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    response = query_engine.query(question)\n",
    "    \n",
    "    print(\"ü§ñ Answer:\")\n",
    "    print(response.response)\n",
    "    \n",
    "    # Show source information\n",
    "    print(f\"\\nüìö Sources used: {len(response.source_nodes)} chunks\")\n",
    "    for i, node in enumerate(response.source_nodes, 1):\n",
    "        print(f\"  Source {i}: {node.metadata.get('file_name', 'Unknown')}\")\n",
    "        print(f\"    Score: {node.score:.3f}\")\n",
    "        print(f\"    Text: {node.text[:150]}...\")\n",
    "        print()\n",
    "    \n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb2b4cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîç Question: What is artificial intelligence?\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 06:50:02,927 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-03 06:50:04,873 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Answer:\n",
      "Artificial intelligence refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. It encompasses machines that exhibit traits associated with a human mind, such as learning and problem-solving.\n",
      "\n",
      "üìö Sources used: 2 chunks\n",
      "  Source 1: sample1.txt\n",
      "    Score: 0.435\n",
      "    Text: Artificial Intelligence and Machine Learning: A Comprehensive Overview\n",
      "\n",
      "Introduction\n",
      "\n",
      "Artificial Intelligence (AI) and Machine Learning (ML) have beco...\n",
      "\n",
      "  Source 2: sample2.txt\n",
      "    Score: 0.256\n",
      "    Text: Serverless Computing:\n",
      "Running applications without managing servers, paying only for actual usage.\n",
      "\n",
      "Container Orchestration:\n",
      "Using technologies like K...\n",
      "\n",
      "\n",
      "============================================================\n",
      "üîç Question: What are the benefits of cloud computing?\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 06:50:05,589 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-03 06:50:08,079 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Answer:\n",
      "Cloud computing offers several benefits, including cost efficiency through reduced capital expenditure on hardware and infrastructure, pay-as-you-use pricing models, and lower operational costs due to economies of scale. It provides scalability and flexibility, allowing rapid scaling up or down based on demand, access to the latest technologies and services, and global reach and availability. Cloud computing also ensures reliability and availability with high uptime guarantees, built-in redundancy, disaster recovery, and professional management and monitoring. Additionally, it fosters innovation and speed by enabling faster time-to-market for applications, access to advanced technologies such as AI, ML, and IoT, and allowing organizations to focus on their core business rather than IT infrastructure.\n",
      "\n",
      "üìö Sources used: 2 chunks\n",
      "  Source 1: sample2.txt\n",
      "    Score: 0.557\n",
      "    Text: Cloud Computing: Transforming Modern Business Infrastructure\n",
      "\n",
      "Introduction\n",
      "\n",
      "Cloud computing has revolutionized how businesses and individuals access, ...\n",
      "\n",
      "  Source 2: sample2.txt\n",
      "    Score: 0.477\n",
      "    Text: Serverless Computing:\n",
      "Running applications without managing servers, paying only for actual usage.\n",
      "\n",
      "Container Orchestration:\n",
      "Using technologies like K...\n",
      "\n",
      "\n",
      "============================================================\n",
      "üîç Question: Explain the different types of machine learning\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 06:50:08,840 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-03 06:50:11,518 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Answer:\n",
      "There are three main types of machine learning:\n",
      "\n",
      "1. Supervised Learning: In this approach, algorithms learn from labeled training data to make predictions on new, unseen data. Common examples include classification and regression problems.\n",
      "\n",
      "2. Unsupervised Learning: Here, algorithms analyze data without labeled examples to find hidden patterns or structures. Techniques such as clustering and dimensionality reduction are commonly used.\n",
      "\n",
      "3. Reinforcement Learning: In this type, algorithms learn by interacting with an environment and receiving rewards or penalties based on their actions, gradually improving their performance over time.\n",
      "\n",
      "üìö Sources used: 2 chunks\n",
      "  Source 1: sample1.txt\n",
      "    Score: 0.427\n",
      "    Text: Artificial Intelligence and Machine Learning: A Comprehensive Overview\n",
      "\n",
      "Introduction\n",
      "\n",
      "Artificial Intelligence (AI) and Machine Learning (ML) have beco...\n",
      "\n",
      "  Source 2: sample2.txt\n",
      "    Score: 0.279\n",
      "    Text: Serverless Computing:\n",
      "Running applications without managing servers, paying only for actual usage.\n",
      "\n",
      "Container Orchestration:\n",
      "Using technologies like K...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with sample questions\n",
    "questions = [\n",
    "    \"What is artificial intelligence?\",\n",
    "    \"What are the benefits of cloud computing?\",\n",
    "    \"Explain the different types of machine learning\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(\"=\" * 60)\n",
    "    test_basic_query(question)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883a96ac",
   "metadata": {},
   "source": [
    "## 5. Advanced Retrieval and Filtering\n",
    "\n",
    "Let's enhance our RAG system with more advanced retrieval strategies and post-processing filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00168bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Advanced query engine created!\n",
      "üìã Enhanced features:\n",
      "  - Similarity filtering (cutoff: 0.7)\n",
      "  - Higher initial retrieval (top 5)\n",
      "  - Post-processing for relevance\n",
      "  - Tree summarization for better responses\n"
     ]
    }
   ],
   "source": [
    "# Create advanced retriever with filters\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.core import get_response_synthesizer\n",
    "\n",
    "# Create retriever with more results initially\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=5,  # Get more results initially\n",
    ")\n",
    "\n",
    "# Add post-processing filters\n",
    "postprocessor = SimilarityPostprocessor(similarity_cutoff=0.7)\n",
    "\n",
    "# Create response synthesizer\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=False,\n",
    ")\n",
    "\n",
    "# Create advanced query engine\n",
    "advanced_query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    node_postprocessors=[postprocessor],\n",
    "    response_synthesizer=response_synthesizer\n",
    ")\n",
    "\n",
    "print(\"üöÄ Advanced query engine created!\")\n",
    "print(\"üìã Enhanced features:\")\n",
    "print(\"  - Similarity filtering (cutoff: 0.7)\")\n",
    "print(\"  - Higher initial retrieval (top 5)\")\n",
    "print(\"  - Post-processing for relevance\")\n",
    "print(\"  - Tree summarization for better responses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7324c615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing document-specific querying:\n",
      "============================================================\n",
      "üîç Querying document: sample1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 06:51:06,002 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Created filtered query engine for: sample1.txt\n",
      "üìÑ Documents included: 1\n",
      "‚ùì Question: What are the main types of artificial intelligence?\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 06:51:07,029 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-03 06:51:08,461 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Answer:\n",
      "The main types of artificial intelligence are:\n",
      "\n",
      "1. Narrow AI (Weak AI): These systems are designed and trained for specific tasks, such as virtual assistants, recommendation algorithms, and image recognition systems.\n",
      "2. General AI (Strong AI): This is a hypothetical form of AI that can understand, learn, and apply knowledge across a wide range of tasks at a level equal to human intelligence.\n",
      "3. Superintelligence: This type of AI would surpass human intelligence in all aspects, including creativity, general wisdom, and social skills.\n",
      "\n",
      "============================================================\n",
      "üîç Querying document: sample2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 06:51:09,280 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Created filtered query engine for: sample2.txt\n",
      "üìÑ Documents included: 1\n",
      "‚ùì Question: What are the cloud service models?\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 06:51:09,793 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-03 06:51:11,588 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Answer:\n",
      "The cloud service models are:\n",
      "\n",
      "1. Infrastructure as a Service (IaaS): Provides virtualized computing resources such as virtual machines, storage, and networking components over the internet on a pay-as-you-go basis.\n",
      "\n",
      "2. Platform as a Service (PaaS): Offers a platform for customers to develop, run, and manage applications without the complexity of building and maintaining the underlying infrastructure.\n",
      "\n",
      "3. Software as a Service (SaaS): Delivers software applications over the internet on a subscription basis, allowing users to access applications through web browsers without local installation or maintenance.\n",
      "üîç Testing Advanced Query Engine with Similarity Filtering\n",
      "============================================================\n",
      "\n",
      "1. Query: What are the main concepts in artificial intelligence?\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 06:51:12,252 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Response: Empty Response\n",
      "\n",
      "\n",
      "2. Query: How does cloud computing work?\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 06:51:12,779 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Response: Empty Response\n",
      "\n",
      "\n",
      "3. Query: What are the benefits of machine learning?\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 06:51:13,172 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Response: Empty Response\n",
      "\n",
      "\n",
      "4. Query: Explain containerization in cloud computing\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 06:51:13,889 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Response: Empty Response\n",
      "\n",
      "‚úÖ Advanced query testing completed!\n"
     ]
    }
   ],
   "source": [
    "# Create a custom query engine that can filter by document source\n",
    "def create_document_specific_query_engine(document_filter=None):\n",
    "    \"\"\"\n",
    "    Create a query engine that can filter by specific documents\n",
    "    \n",
    "    Args:\n",
    "        document_filter: String to match document names (e.g., \"sample1.txt\")\n",
    "    \"\"\"\n",
    "    \n",
    "    if document_filter:\n",
    "        # Filter nodes by document\n",
    "        filtered_nodes = [\n",
    "            node for node in index.docstore.docs.values() \n",
    "            if document_filter.lower() in node.metadata.get('file_name', '').lower()\n",
    "        ]\n",
    "        \n",
    "        if not filtered_nodes:\n",
    "            print(f\"‚ö†Ô∏è No documents found matching filter: {document_filter}\")\n",
    "            return None\n",
    "            \n",
    "        # Create a new index with filtered nodes\n",
    "        from llama_index.core import DocumentSummaryIndex\n",
    "        filtered_docs = [\n",
    "            doc for doc in documents \n",
    "            if document_filter.lower() in doc.metadata.get('file_name', '').lower()\n",
    "        ]\n",
    "        \n",
    "        if filtered_docs:\n",
    "            filtered_index = VectorStoreIndex.from_documents(filtered_docs)\n",
    "            query_engine = filtered_index.as_query_engine(similarity_top_k=3)\n",
    "            print(f\"üéØ Created filtered query engine for: {document_filter}\")\n",
    "            print(f\"üìÑ Documents included: {len(filtered_docs)}\")\n",
    "            return query_engine\n",
    "    \n",
    "    return advanced_query_engine\n",
    "\n",
    "# Test document-specific querying\n",
    "def query_specific_document(question, document_filter=None):\n",
    "    \"\"\"Query a specific document or all documents\"\"\"\n",
    "    \n",
    "    if document_filter:\n",
    "        print(f\"üîç Querying document: {document_filter}\")\n",
    "        engine = create_document_specific_query_engine(document_filter)\n",
    "        if not engine:\n",
    "            return None\n",
    "    else:\n",
    "        print(\"üîç Querying all documents\")\n",
    "        engine = advanced_query_engine\n",
    "    \n",
    "    print(f\"‚ùì Question: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    response = engine.query(question)\n",
    "    print(\"ü§ñ Answer:\")\n",
    "    print(response.response)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Example queries\n",
    "print(\"Testing document-specific querying:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Query about AI from the AI document\n",
    "query_specific_document(\n",
    "    \"What are the main types of artificial intelligence?\", \n",
    "    \"sample1.txt\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Query about cloud computing from the cloud document  \n",
    "query_specific_document(\n",
    "    \"What are the cloud service models?\",\n",
    "    \"sample2.txt\"\n",
    ")\n",
    "\n",
    "# Test advanced query engine with similarity filtering\n",
    "test_queries = [\n",
    "    \"What are the main concepts in artificial intelligence?\",\n",
    "    \"How does cloud computing work?\",\n",
    "    \"What are the benefits of machine learning?\",\n",
    "    \"Explain containerization in cloud computing\"\n",
    "]\n",
    "\n",
    "print(\"üîç Testing Advanced Query Engine with Similarity Filtering\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n{i}. Query: {query}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Query with advanced engine\n",
    "    response = advanced_query_engine.query(query)\n",
    "    print(f\"ü§ñ Response: {response.response}\")\n",
    "    \n",
    "    # Show retrieved nodes information\n",
    "    if hasattr(response, 'source_nodes') and response.source_nodes:\n",
    "        print(f\"üìö Sources used: {len(response.source_nodes)} documents\")\n",
    "        for j, node in enumerate(response.source_nodes[:2]):  # Show first 2 sources\n",
    "            if hasattr(node, 'score'):\n",
    "                print(f\"   - Source {j+1} (similarity: {node.score:.3f})\")\n",
    "            else:\n",
    "                print(f\"   - Source {j+1}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(\"‚úÖ Advanced query testing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0c8207",
   "metadata": {},
   "source": [
    "## 6. Conversational Document Agent\n",
    "\n",
    "Let's create a conversational agent that can maintain context across multiple queries about our documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa156cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Conversational Document Agent created!\n",
      "üéØ Features:\n",
      "  - Maintains conversation context\n",
      "  - Source attribution\n",
      "  - Memory management\n",
      "  - Multi-turn conversations\n"
     ]
    }
   ],
   "source": [
    "# Create a conversational document agent\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "\n",
    "class ConversationalDocumentAgent:\n",
    "    def __init__(self, index, memory_limit=10):\n",
    "        self.index = index\n",
    "        self.memory = ChatMemoryBuffer.from_defaults(token_limit=3000)\n",
    "        self.conversation_history = []\n",
    "        self.memory_limit = memory_limit\n",
    "        \n",
    "        # Create chat engine with memory\n",
    "        self.chat_engine = index.as_chat_engine(\n",
    "            chat_mode=\"context\",\n",
    "            memory=self.memory,\n",
    "            similarity_top_k=3,\n",
    "            system_prompt=(\n",
    "                \"You are a helpful document analysis assistant. \"\n",
    "                \"Answer questions based on the provided document content. \"\n",
    "                \"Always cite the source document when possible. \"\n",
    "                \"If information is not in the documents, clearly state that. \"\n",
    "                \"Maintain conversation context and refer to previous answers when relevant.\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def query(self, question):\n",
    "        \"\"\"Process a query with conversation context\"\"\"\n",
    "        print(f\"üó£Ô∏è User: {question}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Get response from chat engine\n",
    "        response = self.chat_engine.chat(question)\n",
    "        \n",
    "        print(\"ü§ñ Assistant:\")\n",
    "        print(response.response)\n",
    "        \n",
    "        # Add to conversation history\n",
    "        self.conversation_history.append({\n",
    "            \"question\": question,\n",
    "            \"answer\": response.response,\n",
    "            \"sources\": len(response.source_nodes) if hasattr(response, 'source_nodes') else 0\n",
    "        })\n",
    "        \n",
    "        # Keep history manageable\n",
    "        if len(self.conversation_history) > self.memory_limit:\n",
    "            self.conversation_history = self.conversation_history[-self.memory_limit:]\n",
    "        \n",
    "        # Show sources if available\n",
    "        if hasattr(response, 'source_nodes') and response.source_nodes:\n",
    "            print(f\"\\nüìö Sources ({len(response.source_nodes)} chunks):\")\n",
    "            for i, node in enumerate(response.source_nodes, 1):\n",
    "                doc_name = node.metadata.get('file_name', 'Unknown')\n",
    "                print(f\"  {i}. {doc_name} (Score: {node.score:.3f})\")\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def get_conversation_summary(self):\n",
    "        \"\"\"Get a summary of the conversation\"\"\"\n",
    "        return {\n",
    "            \"total_questions\": len(self.conversation_history),\n",
    "            \"questions\": [item[\"question\"] for item in self.conversation_history]\n",
    "        }\n",
    "    \n",
    "    def reset_conversation(self):\n",
    "        \"\"\"Reset the conversation history\"\"\"\n",
    "        self.conversation_history = []\n",
    "        self.memory.reset()\n",
    "        print(\"üîÑ Conversation history reset\")\n",
    "\n",
    "# Create the conversational agent\n",
    "agent = ConversationalDocumentAgent(index)\n",
    "print(\"üí¨ Conversational Document Agent created!\")\n",
    "print(\"üéØ Features:\")\n",
    "print(\"  - Maintains conversation context\")\n",
    "print(\"  - Source attribution\")\n",
    "print(\"  - Memory management\")\n",
    "print(\"  - Multi-turn conversations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1787881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≠ Starting multi-turn conversation:\n",
      "============================================================\n",
      "\n",
      "üîÑ Turn 1:\n",
      "üó£Ô∏è User: What is artificial intelligence?\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 06:52:26,899 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-03 06:52:28,947 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Assistant:\n",
      "Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving. AI can be broadly categorized into:\n",
      "\n",
      "1. **Narrow AI (Weak AI):** AI systems designed and trained for a particular task (e.g., virtual assistants like Siri or Alexa, recommendation algorithms, image recognition systems).\n",
      "2. **General AI (Strong AI):** A hypothetical form of AI that can understand, learn, and apply knowledge across a wide range of tasks at a level equal to human intelligence.\n",
      "3. **Superintelligence:** AI that surpasses human intelligence in all aspects, including creativity, general wisdom, and social skills.\n",
      "\n",
      "(Source: sample1.txt)\n",
      "\n",
      "üìö Sources (3 chunks):\n",
      "  1. sample1.txt (Score: 0.435)\n",
      "  2. sample2.txt (Score: 0.256)\n",
      "  3. sample2.txt (Score: 0.250)\n",
      "\n",
      "‚è≥ (continuing conversation...)\n",
      "\n",
      "üîÑ Turn 2:\n",
      "üó£Ô∏è User: What are the main types you mentioned?\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 06:52:29,640 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-03 06:52:31,812 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Assistant:\n",
      "The main types of artificial intelligence mentioned are:\n",
      "\n",
      "1. **Narrow AI (Weak AI):**  \n",
      "   AI systems that are designed and trained for a particular task. Examples include virtual assistants like Siri or Alexa, recommendation algorithms, and image recognition systems.\n",
      "\n",
      "2. **General AI (Strong AI):**  \n",
      "   A hypothetical form of AI that possesses the ability to understand, learn, and apply knowledge across a wide range of tasks at a level equal to human intelligence.\n",
      "\n",
      "3. **Superintelligence:**  \n",
      "   AI that surpasses human intelligence in all aspects, including creativity, general wisdom, and social skills.\n",
      "\n",
      "(Source: sample1.txt)\n",
      "\n",
      "üìö Sources (3 chunks):\n",
      "  1. sample1.txt (Score: 0.199)\n",
      "  2. sample2.txt (Score: 0.171)\n",
      "  3. sample2.txt (Score: 0.167)\n",
      "\n",
      "‚è≥ (continuing conversation...)\n",
      "\n",
      "üîÑ Turn 3:\n",
      "üó£Ô∏è User: How does this relate to machine learning?\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 06:52:32,231 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-03 06:52:37,036 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Assistant:\n",
      "Artificial Intelligence (AI) is the broader concept of machines being able to carry out tasks in a way that we would consider ‚Äúsmart.‚Äù Machine Learning (ML) is a subset of AI. ML specifically refers to the methods and algorithms that enable computers to learn and improve from experience without being explicitly programmed.\n",
      "\n",
      "Here‚Äôs how they relate:\n",
      "\n",
      "- **AI** is the overarching field focused on creating systems that can perform tasks that typically require human intelligence, such as reasoning, learning, and problem-solving.\n",
      "- **Machine Learning** is one of the main approaches used to achieve AI. Instead of programming explicit rules, ML algorithms build mathematical models based on training data to make predictions or decisions.\n",
      "\n",
      "In summary, all machine learning is AI, but not all AI is machine learning. ML is a key technique that has enabled many recent advances in AI, such as image recognition, natural language processing, and autonomous vehicles.\n",
      "\n",
      "(Source: sample1.txt)\n",
      "\n",
      "üìö Sources (3 chunks):\n",
      "  1. sample1.txt (Score: 0.422)\n",
      "  2. sample2.txt (Score: 0.286)\n",
      "  3. sample2.txt (Score: 0.250)\n",
      "\n",
      "‚è≥ (continuing conversation...)\n",
      "\n",
      "üîÑ Turn 4:\n",
      "üó£Ô∏è User: Now tell me about cloud computing\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 06:52:38,161 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-03 06:52:44,921 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Assistant:\n",
      "Cloud computing is the delivery of computing services‚Äîincluding servers, storage, databases, networking, software, analytics, and intelligence‚Äîover the internet (‚Äúthe cloud‚Äù) to offer faster innovation, flexible resources, and economies of scale. It has revolutionized how businesses and individuals access, store, and process data by providing on-demand access to these resources without the need for direct management or ownership of physical infrastructure.\n",
      "\n",
      "**Essential Characteristics of Cloud Computing:**\n",
      "1. **On-demand self-service:** Users can provision computing capabilities automatically without human interaction with service providers.\n",
      "2. **Broad network access:** Capabilities are available over the network and accessed through standard mechanisms.\n",
      "3. **Resource pooling:** Computing resources are pooled to serve multiple consumers using a multi-tenant model.\n",
      "4. **Rapid elasticity:** Capabilities can be elastically provisioned and released to scale rapidly.\n",
      "5. **Measured service:** Cloud systems automatically control and optimize resource use by leveraging metering capabilities.\n",
      "\n",
      "**Cloud Service Models:**\n",
      "- **Infrastructure as a Service (IaaS):** Provides virtualized computing resources over the internet (e.g., AWS EC2, Microsoft Azure Virtual Machines).\n",
      "- **Platform as a Service (PaaS):** Offers a platform for customers to develop, run, and manage applications without dealing with infrastructure complexity (e.g., Google App Engine, Heroku).\n",
      "- **Software as a Service (SaaS):** Delivers software applications over the internet on a subscription basis (e.g., Salesforce, Microsoft 365).\n",
      "\n",
      "**Cloud Deployment Models:**\n",
      "- **Public Cloud:** Services provided over the public internet and available to anyone.\n",
      "- **Private Cloud:** Cloud infrastructure provisioned for exclusive use by a single organization.\n",
      "- **Hybrid Cloud:** Combines public and private clouds, allowing data and applications to be shared between them.\n",
      "- **Multi-Cloud:** Uses multiple cloud computing services from different providers.\n",
      "\n",
      "**Benefits of Cloud Computing:**\n",
      "- Cost efficiency\n",
      "- Scalability and flexibility\n",
      "- Reliability and availability\n",
      "- Innovation and speed\n",
      "\n",
      "**Challenges and Considerations:**\n",
      "- Security and privacy\n",
      "- Vendor lock-in\n",
      "- Performance and latency\n",
      "- Cost management\n",
      "\n",
      "Cloud computing continues to evolve, with trends such as edge computing, serverless computing, container orchestration, and AI/ML integration shaping its future.\n",
      "\n",
      "(Source: sample2.txt)\n",
      "\n",
      "üìö Sources (3 chunks):\n",
      "  1. sample2.txt (Score: 0.527)\n",
      "  2. sample2.txt (Score: 0.502)\n",
      "  3. sample1.txt (Score: 0.258)\n",
      "\n",
      "‚è≥ (continuing conversation...)\n",
      "\n",
      "üîÑ Turn 5:\n",
      "üó£Ô∏è User: What are the advantages compared to traditional IT infrastructure?\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 06:52:45,640 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-03 06:52:51,575 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Assistant:\n",
      "Cloud computing offers several advantages over traditional IT infrastructure, including:\n",
      "\n",
      "1. **Cost Efficiency**\n",
      "   - **Reduced capital expenditure:** No need to invest heavily in physical hardware and infrastructure.\n",
      "   - **Pay-as-you-use pricing:** Only pay for the resources you actually use.\n",
      "   - **Lower operational costs:** Benefit from economies of scale provided by cloud providers.\n",
      "\n",
      "2. **Scalability and Flexibility**\n",
      "   - **Rapid scaling:** Easily scale resources up or down based on demand.\n",
      "   - **Access to latest technologies:** Instantly use new services and technologies offered by cloud providers.\n",
      "   - **Global reach:** Services are available from anywhere with an internet connection.\n",
      "\n",
      "3. **Reliability and Availability**\n",
      "   - **High uptime guarantees:** Cloud providers often offer 99.9% or higher uptime.\n",
      "   - **Built-in redundancy and disaster recovery:** Data and applications are protected against hardware failures.\n",
      "   - **Professional management:** Cloud providers handle maintenance, monitoring, and updates.\n",
      "\n",
      "4. **Innovation and Speed**\n",
      "   - **Faster time-to-market:** Quickly deploy and update applications.\n",
      "   - **Access to advanced technologies:** Use cutting-edge services like AI, machine learning, and IoT without building them from scratch.\n",
      "   - **Focus on core business:** Organizations can focus on their main business rather than managing IT infrastructure.\n",
      "\n",
      "These advantages make cloud computing a compelling choice for organizations looking to innovate, scale efficiently, and reduce costs compared to maintaining traditional, on-premises IT infrastructure.\n",
      "\n",
      "(Source: sample2.txt)\n",
      "\n",
      "üìö Sources (3 chunks):\n",
      "  1. sample2.txt (Score: 0.491)\n",
      "  2. sample2.txt (Score: 0.442)\n",
      "  3. sample1.txt (Score: 0.236)\n",
      "\n",
      "‚è≥ (continuing conversation...)\n",
      "\n",
      "üîÑ Turn 6:\n",
      "üó£Ô∏è User: Which service model would be best for a startup?\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 06:52:52,395 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-11-03 06:52:59,257 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Assistant:\n",
      "For most startups, **Platform as a Service (PaaS)** is often the best cloud service model. Here‚Äôs why:\n",
      "\n",
      "### Why PaaS is Ideal for Startups:\n",
      "- **Faster Application Development and Deployment:** PaaS provides a ready-to-use platform with tools and frameworks, allowing startups to quickly build, test, and launch applications without worrying about managing servers or infrastructure.\n",
      "- **Reduced Complexity:** Startups can focus on developing their core product rather than handling the complexities of underlying infrastructure, operating systems, or middleware.\n",
      "- **Built-in Scalability and Load Balancing:** PaaS platforms automatically handle scaling and load balancing, which is crucial for startups expecting rapid growth or variable workloads.\n",
      "- **Cost-Effective:** Startups can avoid large upfront investments in hardware and only pay for what they use, making it easier to manage limited budgets.\n",
      "\n",
      "### Examples of PaaS:\n",
      "- Google App Engine\n",
      "- Microsoft Azure App Service\n",
      "- Heroku\n",
      "\n",
      "### When to Consider Other Models:\n",
      "- **IaaS** may be suitable if the startup needs more control over the operating system or wants to run custom environments.\n",
      "- **SaaS** is ideal if the startup only needs to use existing software applications (like email, CRM, or collaboration tools) rather than build their own.\n",
      "\n",
      "**In summary:**  \n",
      "PaaS is generally the best fit for startups aiming to develop and launch applications quickly, with minimal infrastructure management and maximum flexibility.\n",
      "\n",
      "(Source: sample2.txt)\n",
      "\n",
      "üìö Sources (3 chunks):\n",
      "  1. sample2.txt (Score: 0.417)\n",
      "  2. sample2.txt (Score: 0.380)\n",
      "  3. sample1.txt (Score: 0.180)\n",
      "\n",
      "üìä Conversation summary: {'total_questions': 6, 'questions': ['What is artificial intelligence?', 'What are the main types you mentioned?', 'How does this relate to machine learning?', 'Now tell me about cloud computing', 'What are the advantages compared to traditional IT infrastructure?', 'Which service model would be best for a startup?']}\n"
     ]
    }
   ],
   "source": [
    "# Test the conversational agent with a multi-turn conversation\n",
    "conversation_queries = [\n",
    "    \"What is artificial intelligence?\",\n",
    "    \"What are the main types you mentioned?\",\n",
    "    \"How does this relate to machine learning?\",\n",
    "    \"Now tell me about cloud computing\",\n",
    "    \"What are the advantages compared to traditional IT infrastructure?\",\n",
    "    \"Which service model would be best for a startup?\"\n",
    "]\n",
    "\n",
    "print(\"üé≠ Starting multi-turn conversation:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, query in enumerate(conversation_queries, 1):\n",
    "    print(f\"\\nüîÑ Turn {i}:\")\n",
    "    agent.query(query)\n",
    "    \n",
    "    if i < len(conversation_queries):\n",
    "        print(\"\\n‚è≥ (continuing conversation...)\")\n",
    "\n",
    "print(f\"\\nüìä Conversation summary: {agent.get_conversation_summary()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7fe49e",
   "metadata": {},
   "source": [
    "## 7. Advanced Features and Document Analysis\n",
    "\n",
    "Let's explore some advanced features for document analysis and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1b385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced document analysis functions\n",
    "\n",
    "def compare_documents(topic, doc1_filter=None, doc2_filter=None):\n",
    "    \"\"\"Compare how different documents discuss a topic\"\"\"\n",
    "    \n",
    "    print(f\"üìä Comparing documents on topic: {topic}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if doc1_filter and doc2_filter:\n",
    "        # Query each document separately\n",
    "        engine1 = create_document_specific_query_engine(doc1_filter)\n",
    "        engine2 = create_document_specific_query_engine(doc2_filter)\n",
    "        \n",
    "        if engine1 and engine2:\n",
    "            print(f\"üìÑ Document 1: {doc1_filter}\")\n",
    "            response1 = engine1.query(f\"Explain {topic}\")\n",
    "            print(\"ü§ñ Response:\")\n",
    "            print(response1.response)\n",
    "            \n",
    "            print(f\"\\nüìÑ Document 2: {doc2_filter}\")\n",
    "            response2 = engine2.query(f\"Explain {topic}\")\n",
    "            print(\"ü§ñ Response:\")\n",
    "            print(response2.response)\n",
    "            \n",
    "            # Use the main engine to synthesize comparison\n",
    "            print(f\"\\nüîÑ Synthesizing comparison...\")\n",
    "            comparison_query = f\"\"\"\n",
    "            Based on the available documents, compare and contrast how {topic} is presented. \n",
    "            Highlight similarities and differences in the explanations, approaches, or perspectives.\n",
    "            \"\"\"\n",
    "            \n",
    "            comparison_response = advanced_query_engine.query(comparison_query)\n",
    "            print(\"\\nüéØ Comparison Analysis:\")\n",
    "            print(comparison_response.response)\n",
    "    else:\n",
    "        # General comparison query\n",
    "        comparison_query = f\"\"\"\n",
    "        Compare and contrast the different perspectives or approaches to {topic} \n",
    "        found in the available documents. Highlight key similarities and differences.\n",
    "        \"\"\"\n",
    "        response = advanced_query_engine.query(comparison_query)\n",
    "        print(\"ü§ñ Analysis:\")\n",
    "        print(response.response)\n",
    "\n",
    "def summarize_document_collection():\n",
    "    \"\"\"Create a comprehensive summary of all documents\"\"\"\n",
    "    \n",
    "    print(\"üìã Creating comprehensive document summary...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    summary_query = \"\"\"\n",
    "    Provide a comprehensive summary of all the documents in the collection. \n",
    "    Include:\n",
    "    1. Main topics covered\n",
    "    2. Key concepts and definitions\n",
    "    3. Important relationships between topics\n",
    "    4. Overall themes and insights\n",
    "    \n",
    "    Structure your response clearly with headers and bullet points.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = advanced_query_engine.query(summary_query)\n",
    "    print(\"üìä Document Collection Summary:\")\n",
    "    print(response.response)\n",
    "    \n",
    "    return response\n",
    "\n",
    "def extract_key_concepts():\n",
    "    \"\"\"Extract key concepts and definitions from all documents\"\"\"\n",
    "    \n",
    "    print(\"üîë Extracting key concepts and definitions...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    concepts_query = \"\"\"\n",
    "    Extract and list the key concepts, terms, and definitions from all documents.\n",
    "    For each concept, provide:\n",
    "    1. The term/concept name\n",
    "    2. Its definition or explanation\n",
    "    3. Which document(s) it appears in\n",
    "    \n",
    "    Focus on important technical terms, main ideas, and fundamental concepts.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = advanced_query_engine.query(concepts_query)\n",
    "    print(\"üéì Key Concepts:\")\n",
    "    print(response.response)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Test advanced analysis features\n",
    "print(\"üî¨ Advanced Document Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Compare how both documents discuss technology concepts\n",
    "compare_documents(\"the future impact of technology\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Get comprehensive summary\n",
    "summary_response = summarize_document_collection()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Extract key concepts\n",
    "concepts_response = extract_key_concepts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa05ec43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
