{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f47548",
   "metadata": {},
   "source": [
    "pok# Scaling Agentic AI: Live Demo\n",
    "## Building Reliable, Traceable, and High-Impact Systems\n",
    "\n",
    "This notebook demonstrates three layers of agentic AI evolution:\n",
    "1. **Layer 1:** Simple LLM (No memory, no tools)\n",
    "2. **Layer 2:** Single Agent (Memory + Tools)\n",
    "3. **Layer 3:** Multi-Agent System (Router + Specialized Agents)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b5bf75",
   "metadata": {},
   "source": [
    "## Setup: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17cfec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install openai mlflow chromadb python-dotenv -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a8c6e",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04c86c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2d9e99",
   "metadata": {},
   "source": [
    "---\n",
    "# Layer 1: Simple LLM\n",
    "## No Memory, No Tools, No Context\n",
    "\n",
    "**Use Case:** Basic question answering  \n",
    "**Limitations:** \n",
    "- No conversation history\n",
    "- No access to external data\n",
    "- No specialized capabilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe14fc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_llm(user_query):\n",
    "    \"\"\"\n",
    "    Layer 1: Basic LLM with no enhancements\n",
    "    \"\"\"\n",
    "    print(\"üîµ LAYER 1: Simple LLM\")\n",
    "    print(f\"User Query: {user_query}\\n\")\n",
    "    \n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        input=user_query\n",
    "    )\n",
    "    \n",
    "    # print(f\"Response: {response.output_text}\")\n",
    "\n",
    "    return response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ec09eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîµ LAYER 1: Simple LLM\n",
      "User Query: What are the total sales for Q4 2024?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'It looks like you are asking for the total sales for Q4 2024, but I don‚Äôt see any data or table attached to your query.\\n\\nCould you please provide the relevant sales data (table, document, image, or figures) for Q4 2024? Once you provide the data, I can calculate the total sales for you!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demo 1: Single question\n",
    "simple_llm(\"What are the total sales for Q4 2024?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a34ba821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üîµ LAYER 1: Simple LLM\n",
      "User Query: How does that compare to Q3?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'It looks like you‚Äôre asking **how \"that\" compares to Q3**‚Äîbut I don‚Äôt see what ‚Äúthat‚Äù refers to. Could you clarify what specific topic, metric, or data you want compared to Q3? For example: \\n\\n- Company earnings\\n- Economic indicators\\n- Product sales\\n- Website traffic\\n\\nIf you paste relevant Q3 data/details and specify the comparison (is it Q4, current, or something else?), I can give you a precise answer!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demo 2: Follow-up question (no memory)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "simple_llm(\"How does that compare to Q3?\")  # ‚ùå No context from previous question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6b9c7c",
   "metadata": {},
   "source": [
    "### ‚ùå Problem Demonstrated:\n",
    "The LLM has no memory of the previous question. It doesn't know what \"that\" refers to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37470199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950ea2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30ac2a47",
   "metadata": {},
   "source": [
    "---\n",
    "# Layer 2: Single Agent with Memory + Tools\n",
    "## Context-Aware Agent with Function Calling\n",
    "\n",
    "**Enhancements:**\n",
    "- üíæ Conversation memory\n",
    "- üõ†Ô∏è Access to tools (SQL, Calculator, Search)\n",
    "- üß† Can decide when to use tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "398792f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 08:07:16 INFO mlflow.tracking.fluent: Autologging successfully enabled for openai.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MLflow configured\n",
      "Tracking URI: http://127.0.0.1:5000\n",
      "Experiment: text2sql_analysis (id=265088082613722943)\n",
      "Run the MLflow UI with: !mlflow ui --port 5000 &  then open http://localhost:5000 to view traces/experiments.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import os\n",
    "\n",
    "#\n",
    "default_mlrun_path = os.path.abspath(\"mlruns\")\n",
    "mlflow_tracking_uri = os.getenv(\"MLFLOW_TRACKING_URI\", f\"file:{default_mlrun_path}\")\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "\n",
    "# Create / set experiment\n",
    "experiment_name = os.getenv(\"MLFLOW_EXPERIMENT_NAME\", \"agentic-ai-demo\")\n",
    "exp = mlflow.get_experiment_by_name(experiment_name)\n",
    "if exp is None:\n",
    "    exp_id = mlflow.create_experiment(experiment_name)\n",
    "else:\n",
    "    exp_id = exp.experiment_id\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Enable MLflow autologging and OpenAI autolog (if available)\n",
    "mlflow.autolog()  # general autologging for supported libraries\n",
    "\n",
    "try:\n",
    "    # mlflow.openai.autolog() is available in recent mlflow-openai integrations\n",
    "    if hasattr(mlflow, \"openai\") and hasattr(mlflow.openai, \"autolog\"):\n",
    "        mlflow.openai.autolog()\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è mlflow.openai.autolog() not found in this mlflow build. Skipping OpenAI autolog.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Failed to enable mlflow.openai.autolog(): {e}\")\n",
    "\n",
    "print(\"‚úÖ MLflow configured\")\n",
    "print(f\"Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"Experiment: {experiment_name} (id={exp_id})\")\n",
    "print(\"Run the MLflow UI with: !mlflow ui --port 5000 &  then open http://localhost:5000 to view traces/experiments.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d017b23",
   "metadata": {},
   "source": [
    "## In the terminal, run:\n",
    "```\n",
    "mlflow ui\n",
    "```\n",
    "\n",
    "#### to view the logged experiments at http://localhost:5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88137413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tools defined:\n",
      "  - execute_sql: Execute a SQL query against the database to retrieve data\n",
      "  - calculate: Perform mathematical calculations\n"
     ]
    }
   ],
   "source": [
    "# Define available tools\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"execute_sql\",\n",
    "        \"description\": \"Execute a SQL query against the database to retrieve data\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The SQL query to execute\"\n",
    "                },\n",
    "                \"database\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Database name (e.g., 'sales', 'analytics')\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\", \"database\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"calculate\",\n",
    "        \"description\": \"Perform mathematical calculations\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"expression\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Mathematical expression to evaluate\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"expression\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Tools defined:\")\n",
    "for tool in tools:\n",
    "    print(f\"  - {tool['name']}: {tool['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e976d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock tool implementations\n",
    "def execute_sql(query, database):\n",
    "    \"\"\"\n",
    "    Mock SQL execution - simulates database query\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîß Executing SQL on {database}:\")\n",
    "    print(f\"   Query: {query}\")\n",
    "    \n",
    "    # Simulate query results\n",
    "    mock_results = {\n",
    "        \"Q4 2024\": {\"total_sales\": 1250000, \"orders\": 3420},\n",
    "        \"Q3 2024\": {\"total_sales\": 980000, \"orders\": 2890}\n",
    "    }\n",
    "    \n",
    "    if \"Q4\" in query:\n",
    "        return json.dumps(mock_results[\"Q4 2024\"])\n",
    "    elif \"Q3\" in query:\n",
    "        return json.dumps(mock_results[\"Q3 2024\"])\n",
    "    else:\n",
    "        return json.dumps({\"total_sales\": 1250000})\n",
    "\n",
    "def calculate(expression):\n",
    "    \"\"\"\n",
    "    Safe calculator function\n",
    "    \"\"\"\n",
    "    print(f\"\\nüßÆ Calculating: {expression}\")\n",
    "    try:\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return json.dumps({\"result\": result})\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": str(e)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52a2b9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentWithMemory:\n",
    "    \"\"\"\n",
    "    Layer 2: Agent with conversation memory and tool access\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.conversation_history = []\n",
    "    \n",
    "    @mlflow.trace(name=\"agent_with_tools\", span_type=\"AGENT\")\n",
    "    def chat(self, user_message):\n",
    "        print(\"üü¢ LAYER 2: Agent with Memory + Tools\")\n",
    "        print(f\"User: {user_message}\\n\")\n",
    "        \n",
    "        # Add user message to history\n",
    "        self.conversation_history.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_message\n",
    "        })\n",
    "        \n",
    "        # Initial LLM call with tools\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4.1\",\n",
    "            tools=tools,\n",
    "            input=self.conversation_history\n",
    "        )\n",
    "        \n",
    "        # Process tool calls if any\n",
    "        if response.output:\n",
    "            self.conversation_history += response.output\n",
    "            \n",
    "            for item in response.output:\n",
    "                if item.type == \"function_call\":\n",
    "                    print(f\"\\nü§ñ Agent Decision: Call tool '{item.name}'\")\n",
    "                    \n",
    "                    # Execute the appropriate tool\n",
    "                    if item.name == \"execute_sql\":\n",
    "                        args = json.loads(item.arguments)\n",
    "                        result = execute_sql(args['query'], args['database'])\n",
    "                    elif item.name == \"calculate\":\n",
    "                        args = json.loads(item.arguments)\n",
    "                        result = calculate(args['expression'])\n",
    "                    else:\n",
    "                        result = json.dumps({\"error\": \"Unknown tool\"})\n",
    "                    \n",
    "                    # Add tool result to conversation\n",
    "                    self.conversation_history.append({\n",
    "                        \"type\": \"function_call_output\",\n",
    "                        \"call_id\": item.call_id,\n",
    "                        \"output\": result\n",
    "                    })\n",
    "            \n",
    "            # Get final response after tool execution\n",
    "            final_response = client.responses.create(\n",
    "                model=\"gpt-4o\",\n",
    "                tools=tools,\n",
    "                input=self.conversation_history\n",
    "            )\n",
    "            \n",
    "            print(f\"\\n‚úÖ Agent Response: {final_response.output_text}\")\n",
    "            self.conversation_history.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": final_response.output_text\n",
    "            })\n",
    "            \n",
    "            return final_response.output_text\n",
    "        else:\n",
    "            # No tools needed\n",
    "            print(f\"\\n‚úÖ Agent Response: {response.output_text}\")\n",
    "\n",
    "            self.conversation_history.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": response.output_text\n",
    "            })\n",
    "            return response.output_text\n",
    "    \n",
    "    def show_memory(self):\n",
    "        \"\"\"Display conversation history\"\"\"\n",
    "        print(\"\\nüíæ Conversation Memory:\")\n",
    "        for msg in self.conversation_history:\n",
    "            if isinstance(msg, dict) and 'role' in msg:\n",
    "                print(f\"  {msg['role']}: {msg['content'][:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16b621f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üü¢ LAYER 2: Agent with Memory + Tools\n",
      "User: What are the total sales for Q4 2024?\n",
      "\n",
      "\n",
      "ü§ñ Agent Decision: Call tool 'execute_sql'\n",
      "\n",
      "üîß Executing SQL on sales:\n",
      "   Query: SELECT SUM(amount) AS total_sales FROM sales WHERE sale_date >= '2024-10-01' AND sale_date <= '2024-12-31';\n",
      "\n",
      "‚úÖ Agent Response: The total sales for Q4 2024 are $1,250,000.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The total sales for Q4 2024 are $1,250,000.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://127.0.0.1:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-3d2163bd8ae9734f4414fab76bbe8037&amp;experiment_id=265088082613722943&amp;version=3.5.1\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=tr-3d2163bd8ae9734f4414fab76bbe8037)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Demo: Create agent and have a conversation\n",
    "agent = AgentWithMemory()\n",
    "\n",
    "# First question - agent uses SQL tool\n",
    "agent.chat(\"What are the total sales for Q4 2024?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e99cebf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "üü¢ LAYER 2: Agent with Memory + Tools\n",
      "User: How does that compare to Q3?\n",
      "\n",
      "\n",
      "ü§ñ Agent Decision: Call tool 'execute_sql'\n",
      "\n",
      "üîß Executing SQL on sales:\n",
      "   Query: SELECT SUM(amount) AS total_sales FROM sales WHERE sale_date >= '2024-07-01' AND sale_date <= '2024-09-30';\n",
      "\n",
      "‚úÖ Agent Response: The total sales for Q3 2024 were also $1,250,000, so the sales for Q3 and Q4 were the same.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The total sales for Q3 2024 were also $1,250,000, so the sales for Q3 and Q4 were the same.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://127.0.0.1:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-345b044d7ff4d13d5ac7a0bb66e59287&amp;experiment_id=265088082613722943&amp;version=3.5.1\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=tr-345b044d7ff4d13d5ac7a0bb66e59287)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Follow-up question - agent remembers context!\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "agent.chat(\"How does that compare to Q3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3955ff59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 07:12:56 WARNING mlflow.tracing.fluent: Failed to start span Responses: API request to endpoint /api/2.0/mlflow/experiments/get-by-name failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "üü¢ LAYER 2: Agent with Memory + Tools\n",
      "User: What's the percentage growth?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 07:12:58 WARNING mlflow.tracing.fluent: Failed to start span Responses: API request to endpoint /api/2.0/mlflow/experiments/get-by-name failed with error code 403 != 200. Response body: ''. For full traceback, set logging level to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Agent Decision: Call tool 'calculate'\n",
      "\n",
      "üßÆ Calculating: ((1250000 - 1250000) / 1250000) * 100\n",
      "\n",
      "‚úÖ Agent Response: The percentage growth from Q3 to Q4 2024 is 0.0%, indicating no growth.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The percentage growth from Q3 to Q4 2024 is 0.0%, indicating no growth.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate growth percentage\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "agent.chat(\"What's the percentage growth?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8abf11b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Conversation Memory:\n",
      "  user: What are the total sales for Q4 2024?...\n",
      "  assistant: The total sales for Q4 2024 are $1,250,000....\n",
      "  user: How does that compare to Q3?...\n",
      "  assistant: The total sales for Q3 2024 were also $1,250,000, so the sales in Q4 were the sa...\n",
      "  user: What's the percentage growth?...\n",
      "  assistant: The percentage growth from Q3 to Q4 2024 is 0.0%, indicating no growth....\n"
     ]
    }
   ],
   "source": [
    "# Show conversation memory\n",
    "agent.show_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6562c827",
   "metadata": {},
   "source": [
    "### ‚úÖ Improvements Demonstrated:\n",
    "1. **Memory:** Agent remembers previous questions\n",
    "2. **Tool Use:** Automatically calls SQL and calculator tools\n",
    "3. **Context Awareness:** Understands references like \"that\" and \"the percentage\"\n",
    "4. **Traceability:** MLflow captures all decisions and tool calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcf969c",
   "metadata": {},
   "source": [
    "---\n",
    "# Layer 3: Multi-Agent System\n",
    "## Router + Specialized Agents\n",
    "\n",
    "**Architecture:**\n",
    "- üéØ **Router Agent:** Delegates tasks to specialized agents\n",
    "- üìä **SQL Agent:** Handles database queries (Text2SQL)\n",
    "- üìö **RAG Agent:** Retrieves information from documents\n",
    "- üåê **Web Search Agent:** Searches the internet for current information\n",
    "- üîÑ **Consolidator:** Merges outputs from multiple agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbb33733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Specialized agents initialized\n"
     ]
    }
   ],
   "source": [
    "# Define specialized agent tools\n",
    "\n",
    "class SQLAgent:\n",
    "    \"\"\"Specialized agent for SQL queries\"\"\"\n",
    "    \n",
    "    @mlflow.trace(name=\"sql_agent\", span_type=\"AGENT\")\n",
    "    def execute(self, task):\n",
    "        print(\"\\nüìä SQL Agent activated\")\n",
    "        print(f\"   Task: {task}\")\n",
    "        \n",
    "        # Generate and execute SQL\n",
    "        sql_query = f\"SELECT SUM(amount) as total FROM sales WHERE quarter = 'Q4 2024'\"\n",
    "        result = execute_sql(sql_query, \"sales_db\")\n",
    "        \n",
    "        return {\n",
    "            \"agent\": \"SQL\",\n",
    "            \"result\": result,\n",
    "            \"query_used\": sql_query\n",
    "        }\n",
    "\n",
    "class RAGAgent:\n",
    "    \"\"\"Specialized agent for document retrieval\"\"\"\n",
    "    \n",
    "    @mlflow.trace(name=\"rag_agent\", span_type=\"AGENT\")\n",
    "    def execute(self, task):\n",
    "        print(\"\\nüìö RAG Agent activated\")\n",
    "        print(f\"   Task: {task}\")\n",
    "        \n",
    "        # Simulate vector search\n",
    "        print(\"   üîç Searching ChromaDB for relevant documents...\")\n",
    "        \n",
    "        # Mock retrieved context\n",
    "        context = \"\"\"\n",
    "        Q4 2024 Performance Summary:\n",
    "        - Total revenue increased 27.5% YoY\n",
    "        - Top performing region: North America\n",
    "        - New customer acquisition: +15%\n",
    "        - Product category leader: Electronics (40% of sales)\n",
    "        \"\"\"\n",
    "        \n",
    "        return {\n",
    "            \"agent\": \"RAG\",\n",
    "            \"result\": context.strip(),\n",
    "            \"sources\": [\"Q4_2024_report.pdf\", \"sales_summary.md\"]\n",
    "        }\n",
    "\n",
    "class WebSearchAgent:\n",
    "    \"\"\"Specialized agent for web search\"\"\"\n",
    "    \n",
    "    @mlflow.trace(name=\"web_search_agent\", span_type=\"AGENT\")\n",
    "    def execute(self, task):\n",
    "        print(\"\\nüåê Web Search Agent activated\")\n",
    "        print(f\"   Task: {task}\")\n",
    "        \n",
    "        # Use OpenAI's built-in web search\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4o\",\n",
    "            tools=[{\"type\": \"web_search\"}],\n",
    "            input=task\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"agent\": \"WebSearch\",\n",
    "            \"result\": response.output_text,\n",
    "            \"sources\": [\"web_search\"]\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Specialized agents initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1932ffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAgentSystem:\n",
    "    \"\"\"\n",
    "    Layer 3: Multi-agent orchestration system\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.sql_agent = SQLAgent()\n",
    "        self.rag_agent = RAGAgent()\n",
    "        self.web_search_agent = WebSearchAgent()\n",
    "        self.conversation_history = []\n",
    "    \n",
    "    @mlflow.trace(name=\"router_agent\", span_type=\"AGENT\")\n",
    "    def route_task(self, user_query):\n",
    "        \"\"\"\n",
    "        Router agent decides which specialized agents to activate\n",
    "        \"\"\"\n",
    "        print(\"üéØ ROUTER AGENT: Analyzing query...\")\n",
    "        \n",
    "        # Define routing tool\n",
    "        routing_tool = [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"name\": \"delegate_tasks\",\n",
    "                \"description\": \"Delegate tasks to specialized agents\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"tasks\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"agent\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                        \"enum\": [\"sql\", \"rag\", \"web_search\"],\n",
    "                                        \"description\": \"Which agent to use\"\n",
    "                                    },\n",
    "                                    \"task\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                        \"description\": \"Task description for the agent\"\n",
    "                                    }\n",
    "                                },\n",
    "                                \"required\": [\"agent\", \"task\"]\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"tasks\"]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Router decides which agents to use\n",
    "        routing_prompt = f\"\"\"\n",
    "        You are a router agent. Analyze this query and determine which specialized agents to use:\n",
    "        \n",
    "        Query: {user_query}\n",
    "        \n",
    "        Available agents:\n",
    "        - sql: For database queries and numerical data\n",
    "        - rag: For retrieving context from internal documents\n",
    "        - web_search: For current information from the internet\n",
    "        \n",
    "        Delegate appropriate tasks to each agent.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4.1\",\n",
    "            tools=routing_tool,\n",
    "            input=routing_prompt\n",
    "        )\n",
    "        \n",
    "        # Extract routing decisions\n",
    "        delegated_tasks = []\n",
    "        if response.output:\n",
    "            for item in response.output:\n",
    "                if item.type == \"function_call\" and item.name == \"delegate_tasks\":\n",
    "                    args = json.loads(item.arguments)\n",
    "                    delegated_tasks = args.get('tasks', [])\n",
    "        \n",
    "        print(f\"\\n   üìã Delegating to {len(delegated_tasks)} agent(s)\")\n",
    "        return delegated_tasks\n",
    "    \n",
    "    @mlflow.trace(name=\"multi_agent_system\", span_type=\"CHAIN\")\n",
    "    def process(self, user_query):\n",
    "        \"\"\"\n",
    "        Main orchestration flow\n",
    "        \"\"\"\n",
    "        print(\"üü£ LAYER 3: Multi-Agent System\")\n",
    "        print(f\"User Query: {user_query}\\n\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Step 1: Router delegates tasks\n",
    "        tasks = self.route_task(user_query)\n",
    "        \n",
    "        # Step 2: Execute tasks in parallel (simulated)\n",
    "        agent_results = []\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"‚öôÔ∏è  EXECUTING SUB-AGENTS\")\n",
    "        \n",
    "        for task_info in tasks:\n",
    "            agent_type = task_info['agent']\n",
    "            task = task_info['task']\n",
    "            \n",
    "            if agent_type == \"sql\":\n",
    "                result = self.sql_agent.execute(task)\n",
    "            elif agent_type == \"rag\":\n",
    "                result = self.rag_agent.execute(task)\n",
    "            elif agent_type == \"web_search\":\n",
    "                result = self.web_search_agent.execute(task)\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            agent_results.append(result)\n",
    "        \n",
    "        # Step 3: Consolidate results\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        final_response = self.consolidate_results(user_query, agent_results)\n",
    "        \n",
    "        return final_response\n",
    "    \n",
    "    @mlflow.trace(name=\"consolidation_agent\", span_type=\"AGENT\")\n",
    "    def consolidate_results(self, original_query, agent_results):\n",
    "        \"\"\"\n",
    "        Consolidation agent merges outputs from all sub-agents\n",
    "        \"\"\"\n",
    "        print(\"üîÑ CONSOLIDATION AGENT: Merging results...\\n\")\n",
    "        \n",
    "        # Prepare context from all agents\n",
    "        context = f\"Original query: {original_query}\\n\\nResults from specialized agents:\\n\\n\"\n",
    "        \n",
    "        for idx, result in enumerate(agent_results, 1):\n",
    "            context += f\"{idx}. {result['agent']} Agent:\\n\"\n",
    "            context += f\"   {result['result']}\\n\\n\"\n",
    "        \n",
    "        # Generate consolidated response\n",
    "        consolidation_prompt = f\"\"\"\n",
    "        {context}\n",
    "        \n",
    "        Synthesize the above information into a comprehensive, coherent answer to the user's query.\n",
    "        Include all relevant data points and insights from the specialized agents.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4o\",\n",
    "            input=consolidation_prompt\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Final Consolidated Response:\\n\")\n",
    "        print(response.output_text)\n",
    "        \n",
    "        return {\n",
    "            \"response\": response.output_text,\n",
    "            \"agent_results\": agent_results,\n",
    "            \"num_agents_used\": len(agent_results)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53d3e890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üü£ LAYER 3: Multi-Agent System\n",
      "User Query: Give me a comprehensive analysis of Q4 2024 sales performance with context from our reports\n",
      "\n",
      "======================================================================\n",
      "üéØ ROUTER AGENT: Analyzing query...\n",
      "\n",
      "   üìã Delegating to 2 agent(s)\n",
      "\n",
      "======================================================================\n",
      "‚öôÔ∏è  EXECUTING SUB-AGENTS\n",
      "\n",
      "üìä SQL Agent activated\n",
      "   Task: Extract detailed sales performance metrics for Q4 2024, including key figures such as revenue, units sold, growth rates, and any regional or product breakdowns available.\n",
      "\n",
      "üîß Executing SQL on sales_db:\n",
      "   Query: SELECT SUM(amount) as total FROM sales WHERE quarter = 'Q4 2024'\n",
      "\n",
      "üìö RAG Agent activated\n",
      "   Task: Retrieve contextual information and insights about Q4 2024 sales performance by analyzing our internal reports, highlighting any factors, challenges, or notable trends mentioned.\n",
      "   üîç Searching ChromaDB for relevant documents...\n",
      "\n",
      "======================================================================\n",
      "üîÑ CONSOLIDATION AGENT: Merging results...\n",
      "\n",
      "‚úÖ Final Consolidated Response:\n",
      "\n",
      "In Q4 2024, our sales performance demonstrated significant growth and success. The total sales amounted to $1,250,000, with 3,420 orders processed. This represents a substantial 27.5% increase in total revenue year-over-year, indicating strong market resilience and effective strategies.\n",
      "\n",
      "North America emerged as the top-performing region, contributing significantly to this growth. Additionally, new customer acquisition saw a notable rise of 15%, showcasing our expanding customer base and effective outreach efforts.\n",
      "\n",
      "Within our product offerings, the Electronics category led the way, accounting for 40% of total sales. This highlights both strong demand in this sector and the effectiveness of our product strategies within this category.\n",
      "\n",
      "Overall, Q4 2024 was marked by robust performance across key metrics, underscoring our strategic successes and setting a strong foundation for future growth.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://127.0.0.1:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-9c2dc02355f5021b6baf9709ca07fe50&amp;experiment_id=265088082613722943&amp;version=3.5.1\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=tr-9c2dc02355f5021b6baf9709ca07fe50)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Demo: Complex query requiring multiple agents\n",
    "mas = MultiAgentSystem()\n",
    "\n",
    "query = \"Give me a comprehensive analysis of Q4 2024 sales performance with context from our reports\"\n",
    "\n",
    "result = mas.process(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee04c041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìä EXECUTION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Agents activated: 2\n",
      "\n",
      "Agent breakdown:\n",
      "  ‚úì SQL Agent\n",
      "  ‚úì RAG Agent\n",
      "    Sources: Q4_2024_report.pdf, sales_summary.md\n"
     ]
    }
   ],
   "source": [
    "# Show which agents were used\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä EXECUTION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nAgents activated: {result['num_agents_used']}\")\n",
    "print(\"\\nAgent breakdown:\")\n",
    "for agent_result in result['agent_results']:\n",
    "    print(f\"  ‚úì {agent_result['agent']} Agent\")\n",
    "    if 'sources' in agent_result:\n",
    "        print(f\"    Sources: {', '.join(agent_result['sources'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831f2102",
   "metadata": {},
   "source": [
    "### ‚úÖ Multi-Agent System Benefits:\n",
    "\n",
    "1. **Task Specialization:** Each agent is optimized for specific tasks\n",
    "2. **Parallel Execution:** Multiple agents can work simultaneously\n",
    "3. **Modularity:** Easy to add new agents without changing existing ones\n",
    "4. **Comprehensive Responses:** Combines data from multiple sources\n",
    "5. **Full Traceability:** MLflow captures every agent decision and execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1167fbd5",
   "metadata": {},
   "source": [
    "---\n",
    "# MLflow Tracing: View Agent Decisions\n",
    "\n",
    "All agent executions are automatically traced by MLflow. To view traces:\n",
    "\n",
    "```bash\n",
    "mlflow ui\n",
    "```\n",
    "\n",
    "Then navigate to: http://localhost:5000\n",
    "\n",
    "**What you'll see:**\n",
    "- üïí Latency per agent\n",
    "- üîç Tool calls and decisions\n",
    "- üìä Execution flow (router ‚Üí sub-agents ‚Üí consolidation)\n",
    "- üí∞ Token usage and costs\n",
    "- ‚ö†Ô∏è Errors and retries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701bcc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start MLflow UI (in background)\n",
    "!mlflow ui --port 5000 &"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7055d8",
   "metadata": {},
   "source": [
    "---\n",
    "# Comparison Summary\n",
    "\n",
    "| Feature | Layer 1 | Layer 2 | Layer 3 |\n",
    "|---------|---------|---------|----------|\n",
    "| **Memory** | ‚ùå | ‚úÖ | ‚úÖ |\n",
    "| **Tools** | ‚ùå | ‚úÖ | ‚úÖ |\n",
    "| **Agents** | 0 | 1 | Multiple |\n",
    "| **Orchestration** | ‚ùå | ‚ùå | ‚úÖ Router |\n",
    "| **Specialization** | ‚ùå | ‚ùå | ‚úÖ |\n",
    "| **Parallel Execution** | ‚ùå | ‚ùå | ‚úÖ |\n",
    "| **Scalability** | Low | Medium | High |\n",
    "| **Complexity** | Low | Medium | High |\n",
    "| **Use Case** | Simple Q&A | Interactive chat with tools | Complex multi-step tasks |\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways:\n",
    "\n",
    "1. **Start Simple:** Layer 1 is fine for basic tasks\n",
    "2. **Add Memory First:** Layer 2 dramatically improves UX\n",
    "3. **Scale with Specialization:** Layer 3 for complex, multi-faceted problems\n",
    "4. **Trace Everything:** MLflow makes debugging and optimization possible\n",
    "5. **Build Modular:** Function calling enables plug-and-play architecture\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d008d1dc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
